# Database Design Documentation
# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë¬¸ì„œ

**Last Updated**: 2025-10-25
**Database**: `browserstack` (MariaDB/MySQL)

---

## ğŸ“‹ Table of Contents

1. [Overview](#overview)
2. [Table Schemas](#table-schemas)
3. [Table Relationships](#table-relationships)
4. [Data Flow](#data-flow)
5. [Query Patterns](#query-patterns)
6. [Indexing Strategy](#indexing-strategy)
7. [Usage Examples](#usage-examples)

---

## Overview
## ê°œìš”

The `browserstack` database stores all data related to TLS fingerprinting, cookie management, and web crawling results from BrowserStack real devices.

`browserstack` ë°ì´í„°ë² ì´ìŠ¤ëŠ” BrowserStack ì‹¤ê¸°ê¸°ì—ì„œ ìˆ˜ì§‘í•œ TLS ì§€ë¬¸, ì¿ í‚¤ ê´€ë¦¬, ì›¹ í¬ë¡¤ë§ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

**Database Philosophy**:
- **Append-Only for TLS/Cookies**: Never delete old fingerprints - track variance over time
- **Session-Based Tracking**: All crawl operations linked by `session_id`
- **Rich Metadata**: Capture detailed error types, timings, and Akamai detection
- **Analysis-Ready**: Optimized for retrospective analysis and debugging

**ë°ì´í„°ë² ì´ìŠ¤ ì² í•™**:
- **TLS/ì¿ í‚¤ëŠ” ì¶”ê°€ë§Œ**: ì˜¤ë˜ëœ ì§€ë¬¸ì„ ì‚­ì œí•˜ì§€ ì•ŠìŒ - ì‹œê°„ì— ë”°ë¥¸ ë³€ë™ì„± ì¶”ì 
- **ì„¸ì…˜ ê¸°ë°˜ ì¶”ì **: ëª¨ë“  í¬ë¡¤ë§ ì‘ì—…ì„ `session_id`ë¡œ ì—°ê²°
- **í’ë¶€í•œ ë©”íƒ€ë°ì´í„°**: ìƒì„¸í•œ ì—ëŸ¬ íƒ€ì…, íƒ€ì´ë°, Akamai íƒì§€ ì •ë³´ ì €ì¥
- **ë¶„ì„ ì¤€ë¹„**: íšŒê³ ì  ë¶„ì„ ë° ë””ë²„ê¹…ì— ìµœì í™”

---

## Table Schemas
## í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ

### 1. `tls_fingerprints` - TLS ì§€ë¬¸ ì €ì¥ì†Œ

**Purpose**: Store TLS fingerprints collected from real devices (append-only)

**ëª©ì **: ì‹¤ê¸°ê¸°ì—ì„œ ìˆ˜ì§‘í•œ TLS ì§€ë¬¸ ì €ì¥ (ì¶”ê°€ ì „ìš©)

```sql
CREATE TABLE tls_fingerprints (
  id                  BIGINT AUTO_INCREMENT PRIMARY KEY,
  device_name         VARCHAR(100) NOT NULL,
  browser             VARCHAR(50) NOT NULL,
  os_version          VARCHAR(20) NOT NULL,

  -- Full TLS/HTTP2 data (JSON)
  tls_data            LONGTEXT NOT NULL,      -- TLS extension, ciphers, ja3, etc.
  http2_data          LONGTEXT NOT NULL,      -- Akamai fingerprint, sent_frames, etc.

  -- Quick lookup fields (extracted from JSON)
  ja3_hash            VARCHAR(64),
  akamai_fingerprint  VARCHAR(100),
  peetprint_hash      VARCHAR(64),

  -- Statistics
  cipher_count        INT,
  extension_count     INT,

  -- Timestamps
  collected_at        DATETIME NOT NULL,      -- When BrowserStack collected this
  created_at          TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at          TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

  -- Indexes
  INDEX idx_device (device_name, browser, os_version),
  INDEX idx_ja3 (ja3_hash),
  INDEX idx_akamai (akamai_fingerprint),
  INDEX idx_collected (collected_at)
);
```

**Key Fields**:
- `tls_data`: Full TLS fingerprint from https://tls.peet.ws/api/all
  - Contains: ciphers, extensions, ja3, ja3_hash, ja4, peetprint, etc.
- `http2_data`: HTTP/2 fingerprint
  - Contains: akamai_fingerprint, akamai_fingerprint_hash, sent_frames
- `ja3_hash`: Quick lookup (varies per session due to GREASE)
- `akamai_fingerprint`: Quick lookup (stable across sessions)

**ì£¼ìš” í•„ë“œ**:
- `tls_data`: https://tls.peet.ws/api/all ì—ì„œ ê°€ì ¸ì˜¨ ì „ì²´ TLS ì§€ë¬¸
  - í¬í•¨ ë‚´ìš©: ciphers, extensions, ja3, ja3_hash, ja4, peetprint ë“±
- `http2_data`: HTTP/2 ì§€ë¬¸
  - í¬í•¨ ë‚´ìš©: akamai_fingerprint, akamai_fingerprint_hash, sent_frames
- `ja3_hash`: ë¹ ë¥¸ ì¡°íšŒìš© (GREASEë¡œ ì¸í•´ ì„¸ì…˜ë§ˆë‹¤ ë³€ë™)
- `akamai_fingerprint`: ë¹ ë¥¸ ì¡°íšŒìš© (ì„¸ì…˜ ê°„ ì•ˆì •ì )

**Important**: This table is **append-only**. Never UPDATE or DELETE records.
**ì¤‘ìš”**: ì´ í…Œì´ë¸”ì€ **ì¶”ê°€ ì „ìš©**ì…ë‹ˆë‹¤. ë ˆì½”ë“œë¥¼ UPDATEë‚˜ DELETEí•˜ì§€ ë§ˆì„¸ìš”.

---

### 2. `cookies` - ì¿ í‚¤ ì €ì¥ì†Œ

**Purpose**: Store cookies collected from Coupang (append-only with lifecycle tracking)

**ëª©ì **: ì¿ íŒ¡ì—ì„œ ìˆ˜ì§‘í•œ ì¿ í‚¤ ì €ì¥ (ì¶”ê°€ ì „ìš©, ìƒëª…ì£¼ê¸° ì¶”ì )

```sql
CREATE TABLE cookies (
  id                BIGINT AUTO_INCREMENT PRIMARY KEY,
  device_name       VARCHAR(100) NOT NULL,
  browser           VARCHAR(50) NOT NULL,
  os_version        VARCHAR(20) NOT NULL,

  -- Cookie metadata
  cookie_type       ENUM('original', 'updated') NOT NULL,  -- original: from BrowserStack, updated: from crawl
  cookie_data       LONGTEXT NOT NULL,                     -- JSON array of cookies

  -- Session context
  session_id        VARCHAR(50),                           -- Which crawl session used this
  page_number       INT,                                   -- Which page updated this

  -- Lifecycle tracking
  collected_at      TIMESTAMP NOT NULL,
  is_valid          BOOLEAN DEFAULT TRUE,
  last_used_at      TIMESTAMP,
  use_count         INT DEFAULT 0,
  success_pages     INT DEFAULT 0,
  failed_pages      INT DEFAULT 0,

  created_at        TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at        TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

  -- Indexes
  INDEX idx_device (device_name, browser, os_version),
  INDEX idx_type (cookie_type),
  INDEX idx_collected (collected_at),
  INDEX idx_session (session_id),
  INDEX idx_valid (is_valid)
);
```

**Key Fields**:
- `cookie_type`:
  - `original`: Initial cookies from BrowserStack dynamic collection
  - `updated`: Cookies updated during multi-page crawling (Set-Cookie)
- `cookie_data`: JSON array with cookies (PCID, sid, _abck, etc.)
- `is_valid`: Tracks if cookies are still working
- `success_pages` / `failed_pages`: Performance tracking

**ì£¼ìš” í•„ë“œ**:
- `cookie_type`:
  - `original`: BrowserStack ë™ì  ìˆ˜ì§‘ì—ì„œ ê°€ì ¸ì˜¨ ì´ˆê¸° ì¿ í‚¤
  - `updated`: ë‹¤ì¤‘ í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘ ì—…ë°ì´íŠ¸ëœ ì¿ í‚¤ (Set-Cookie)
- `cookie_data`: ì¿ í‚¤ ë°°ì—´ JSON (PCID, sid, _abck ë“±)
- `is_valid`: ì¿ í‚¤ê°€ ì—¬ì „íˆ ì‘ë™í•˜ëŠ”ì§€ ì¶”ì 
- `success_pages` / `failed_pages`: ì„±ëŠ¥ ì¶”ì 

**Lifecycle**:
1. Initial collection â†’ `cookie_type = 'original'`
2. Crawl updates cookies â†’ New record with `cookie_type = 'updated'`
3. Track success/failure â†’ Update `is_valid`, `success_pages`, `failed_pages`

**ìƒëª…ì£¼ê¸°**:
1. ì´ˆê¸° ìˆ˜ì§‘ â†’ `cookie_type = 'original'`
2. í¬ë¡¤ë§ ì¤‘ ì¿ í‚¤ ì—…ë°ì´íŠ¸ â†’ `cookie_type = 'updated'`ë¡œ ìƒˆ ë ˆì½”ë“œ
3. ì„±ê³µ/ì‹¤íŒ¨ ì¶”ì  â†’ `is_valid`, `success_pages`, `failed_pages` ì—…ë°ì´íŠ¸

---

### 3. `products` - ìƒí’ˆ ë°ì´í„°

**Purpose**: Store all products (ranking + ads) from Coupang search results

**ëª©ì **: ì¿ íŒ¡ ê²€ìƒ‰ ê²°ê³¼ì˜ ëª¨ë“  ìƒí’ˆ (ë­í‚¹ + ê´‘ê³ ) ì €ì¥

```sql
CREATE TABLE products (
  id                 BIGINT AUTO_INCREMENT PRIMARY KEY,

  -- Session context
  session_id         VARCHAR(50) NOT NULL,
  device_name        VARCHAR(100) NOT NULL,
  browser            VARCHAR(50) NOT NULL,
  os_version         VARCHAR(20) NOT NULL,

  -- Search context
  keyword            VARCHAR(200) NOT NULL,
  page_number        INT NOT NULL,

  -- Product classification
  product_type       ENUM('ranking', 'ad') NOT NULL,

  -- Product details
  product_name       VARCHAR(500),
  product_price      VARCHAR(100),
  product_url        VARCHAR(1000),
  product_image_url  VARCHAR(1000),

  -- Ranking products
  rank_position      INT,                    -- 1, 2, 3, ...

  -- Ad products
  ad_slot            VARCHAR(50),            -- "row_1_col_1", "bottom_1", etc.
  ad_type            VARCHAR(50),            -- "SPONSORED", "ROCKET", etc.
  ad_position        INT,                    -- Order within same slot type

  collected_at       TIMESTAMP NOT NULL,

  -- Indexes
  INDEX idx_session (session_id),
  INDEX idx_device (device_name, browser, os_version),
  INDEX idx_keyword (keyword),
  INDEX idx_type (product_type),
  INDEX idx_collected (collected_at)
);
```

**Key Fields**:
- `product_type`: Distinguishes ranking vs. ad products
- `rank_position`: For ranking products (1-based)
- `ad_slot`: Grid position for ads (e.g., "row_1_col_1")
- `ad_type`: SPONSORED, ROCKET, etc.

**ì£¼ìš” í•„ë“œ**:
- `product_type`: ë­í‚¹ vs. ê´‘ê³  ìƒí’ˆ êµ¬ë¶„
- `rank_position`: ë­í‚¹ ìƒí’ˆì˜ ìˆœìœ„ (1ë¶€í„° ì‹œì‘)
- `ad_slot`: ê´‘ê³ ì˜ ê·¸ë¦¬ë“œ ìœ„ì¹˜ (ì˜ˆ: "row_1_col_1")
- `ad_type`: SPONSORED, ROCKET ë“±

**Query Pattern**:
```sql
-- Get all ranking products for a session
SELECT * FROM products
WHERE session_id = '20251025_123456'
  AND product_type = 'ranking'
ORDER BY page_number, rank_position;

-- Ad distribution analysis
SELECT ad_slot, COUNT(*) as count
FROM products
WHERE product_type = 'ad'
GROUP BY ad_slot;
```

---

### 4. `crawl_details` - í¬ë¡¤ë§ ìƒì„¸ ì •ë³´

**Purpose**: Record every crawl attempt (success or failure) with detailed metrics

**ëª©ì **: ëª¨ë“  í¬ë¡¤ë§ ì‹œë„ (ì„±ê³µ/ì‹¤íŒ¨)ë¥¼ ìƒì„¸í•œ ì§€í‘œì™€ í•¨ê»˜ ê¸°ë¡

```sql
CREATE TABLE crawl_details (
  id                      BIGINT AUTO_INCREMENT PRIMARY KEY,

  -- Session context
  session_id              VARCHAR(50) NOT NULL,
  device_name             VARCHAR(100) NOT NULL,
  browser                 VARCHAR(50) NOT NULL,
  os_version              VARCHAR(20) NOT NULL,

  -- Crawl target
  keyword                 VARCHAR(200) NOT NULL,
  page_number             INT NOT NULL,
  worker_id               INT,                    -- For parallel crawling

  -- Outcome
  status                  ENUM(
                            'success',
                            'http2_error',
                            'akamai_challenge',
                            'no_products',
                            'network_error',
                            'timeout',
                            'parsing_error',
                            'unknown_error'
                          ) NOT NULL,
  error_message           TEXT,
  error_type              VARCHAR(100),

  -- HTTP metrics
  response_size_bytes     INT,
  response_time_ms        INT,
  http_status_code        INT,

  -- Akamai detection
  is_akamai_blocked       BOOLEAN,
  akamai_challenge_type   VARCHAR(50),           -- 'bm_sc_challenge', 'akamai_page', etc.
  bm_sc_cookie            VARCHAR(500),          -- Challenge cookie if blocked

  -- Product counts (for success)
  ranking_products_count  INT,
  ad_products_count       INT,
  total_products_count    INT,

  -- Cookie context
  cookie_source           VARCHAR(20),           -- 'original', 'updated', 'session'
  cookie_count            INT,
  has_pcid                BOOLEAN,
  has_sid                 BOOLEAN,

  -- Retry tracking
  attempt_number          INT,
  max_attempts            INT,

  crawled_at              TIMESTAMP NOT NULL,

  -- Indexes
  INDEX idx_session (session_id),
  INDEX idx_device (device_name, browser, os_version),
  INDEX idx_status (status),
  INDEX idx_akamai (is_akamai_blocked),
  INDEX idx_crawled (crawled_at)
);
```

**Key Fields**:
- `status`: Precise error categorization (8 types)
- `is_akamai_blocked`: Quick filter for Akamai blocks
- `akamai_challenge_type`: Specific Akamai challenge detected
- `response_size_bytes`: Detect blocks (< 5KB typically)
- `attempt_number` / `max_attempts`: Retry tracking

**ì£¼ìš” í•„ë“œ**:
- `status`: ì •ë°€í•œ ì—ëŸ¬ ë¶„ë¥˜ (8ê°€ì§€ íƒ€ì…)
- `is_akamai_blocked`: Akamai ì°¨ë‹¨ ë¹ ë¥¸ í•„í„°
- `akamai_challenge_type`: ê°ì§€ëœ íŠ¹ì • Akamai ì±Œë¦°ì§€
- `response_size_bytes`: ì°¨ë‹¨ ê°ì§€ (ì¼ë°˜ì ìœ¼ë¡œ < 5KB)
- `attempt_number` / `max_attempts`: ì¬ì‹œë„ ì¶”ì 

**Analysis Queries**:
```sql
-- Akamai block rate by device
SELECT device_name, browser,
       COUNT(*) as total_attempts,
       SUM(is_akamai_blocked) as blocked,
       ROUND(100.0 * SUM(is_akamai_blocked) / COUNT(*), 2) as block_rate
FROM crawl_details
GROUP BY device_name, browser
ORDER BY block_rate DESC;

-- Success rate by hour
SELECT HOUR(crawled_at) as hour,
       COUNT(*) as total,
       SUM(status = 'success') as success,
       ROUND(100.0 * SUM(status = 'success') / COUNT(*), 2) as success_rate
FROM crawl_details
GROUP BY hour
ORDER BY hour;
```

---

### 5. `crawl_results` - í¬ë¡¤ë§ ì„¸ì…˜ ìš”ì•½

**Purpose**: Aggregate results for each complete crawl session

**ëª©ì **: ê° í¬ë¡¤ë§ ì„¸ì…˜ì˜ ì „ì²´ ê²°ê³¼ ì§‘ê³„

```sql
CREATE TABLE crawl_results (
  id                BIGINT AUTO_INCREMENT PRIMARY KEY,

  -- Session identification
  session_id        VARCHAR(50) NOT NULL UNIQUE,
  device_name       VARCHAR(100) NOT NULL,
  browser           VARCHAR(50) NOT NULL,
  os_version        VARCHAR(20) NOT NULL,

  -- Crawl parameters
  keyword           VARCHAR(200) NOT NULL,
  pages_start       INT NOT NULL,
  pages_end         INT NOT NULL,
  workers           INT,                    -- Parallel workers used

  -- Outcome summary
  pages_successful  INT,
  pages_failed      INT,
  total_ranking     INT,
  total_ads         INT,
  status            ENUM('success', 'partial', 'failed'),

  -- Performance
  duration_seconds  FLOAT,

  -- Time analysis
  hour              TINYINT,                -- 0-23
  day_of_week       VARCHAR(10),            -- Monday, Tuesday, ...

  -- Detailed data (JSON)
  full_results      LONGTEXT,               -- Complete crawl results
  errors            LONGTEXT,               -- Array of error details

  created_at        TIMESTAMP,

  -- Indexes
  INDEX idx_session (session_id),
  INDEX idx_device (device_name, browser, os_version),
  INDEX idx_keyword (keyword),
  INDEX idx_status (status),
  INDEX idx_hour (hour),
  INDEX idx_created (created_at)
);
```

**Key Fields**:
- `status`:
  - `success`: All pages crawled successfully
  - `partial`: Some pages failed
  - `failed`: All pages failed
- `hour` / `day_of_week`: Time-based analysis (best crawl times)
- `full_results`: Complete JSON for detailed analysis
- `errors`: Array of all errors encountered

**ì£¼ìš” í•„ë“œ**:
- `status`:
  - `success`: ëª¨ë“  í˜ì´ì§€ í¬ë¡¤ë§ ì„±ê³µ
  - `partial`: ì¼ë¶€ í˜ì´ì§€ ì‹¤íŒ¨
  - `failed`: ëª¨ë“  í˜ì´ì§€ ì‹¤íŒ¨
- `hour` / `day_of_week`: ì‹œê°„ëŒ€ ë¶„ì„ (ìµœì  í¬ë¡¤ë§ ì‹œê°„)
- `full_results`: ìƒì„¸ ë¶„ì„ìš© ì™„ì „í•œ JSON
- `errors`: ë°œìƒí•œ ëª¨ë“  ì—ëŸ¬ ë°°ì—´

---

### 6. `device_selections` - ë””ë°”ì´ìŠ¤ ì„ íƒ ì´ë ¥

**Purpose**: Track last selected device for default value in selector

**ëª©ì **: ì„ íƒê¸°ì˜ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©í•  ë§ˆì§€ë§‰ ì„ íƒ ë””ë°”ì´ìŠ¤ ì¶”ì 

```sql
CREATE TABLE device_selections (
  id            BIGINT AUTO_INCREMENT PRIMARY KEY,
  device_name   VARCHAR(100) NOT NULL,
  browser       VARCHAR(50) NOT NULL,
  os_version    VARCHAR(20) NOT NULL,
  category      VARCHAR(50),            -- Galaxy, iPhone, etc.
  selected_at   TIMESTAMP,

  INDEX idx_device (device_name),
  INDEX idx_selected (selected_at)
);
```

**Usage**: Keep only latest N selections for quick lookup.

**ì‚¬ìš©ë²•**: ë¹ ë¥¸ ì¡°íšŒë¥¼ ìœ„í•´ ìµœê·¼ Nê°œ ì„ íƒë§Œ ìœ ì§€.

---

### 7. `changelogs` - ë³€ê²½ ì´ë ¥

**Purpose**: Document all significant changes, discoveries, and fixes

**ëª©ì **: ëª¨ë“  ì¤‘ìš”í•œ ë³€ê²½ì‚¬í•­, ë°œê²¬, ìˆ˜ì • ì‚¬í•­ ë¬¸ì„œí™”

```sql
CREATE TABLE changelogs (
  id              BIGINT AUTO_INCREMENT PRIMARY KEY,
  version         VARCHAR(20) NOT NULL,
  release_date    DATE NOT NULL,
  category        ENUM('feature', 'fix', 'improvement', 'analysis', 'refactor', 'discovery') NOT NULL,
  impact          ENUM('critical', 'major', 'minor') NOT NULL,

  -- Content
  title           VARCHAR(200) NOT NULL,
  description     TEXT,
  files_changed   TEXT,                   -- JSON array of file paths
  code_reference  VARCHAR(200),           -- File:line reference

  -- Metadata
  tags            VARCHAR(500),           -- Comma-separated tags
  tls_extension   VARCHAR(100),           -- If related to TLS (ECH, ALPS, etc.)
  browser_affected VARCHAR(100),          -- Which browsers affected

  created_at      TIMESTAMP,

  -- Indexes
  INDEX idx_version (version),
  INDEX idx_date (release_date),
  INDEX idx_category (category),
  INDEX idx_impact (impact),
  INDEX idx_tags (tags)
);
```

**Example Entry**:
```sql
INSERT INTO changelogs VALUES (
  NULL, 'v2.10', '2025-10-24', 'discovery', 'critical',
  'X25519MLKEM768 identified as sole blocking factor',
  'Confirmed that X25519MLKEM768 extension (4588) is the only reason for Akamai blocking. ECH and ALPS are irrelevant.',
  '["CLAUDE.md"]',
  'CLAUDE.md:125-150',
  'tls,akamai,blocking,x25519mlkem768',
  'X25519MLKEM768',
  'Chromium 124+',
  NOW()
);
```

---

### 8. `tls_variance_samples` - TLS ë³€ë™ì„± ìƒ˜í”Œ

**Purpose**: Store multiple TLS collections from same device for variance analysis

**ëª©ì **: ë³€ë™ì„± ë¶„ì„ì„ ìœ„í•´ ë™ì¼ ë””ë°”ì´ìŠ¤ì˜ ì—¬ëŸ¬ TLS ìˆ˜ì§‘ ì €ì¥

```sql
CREATE TABLE tls_variance_samples (
  id                 BIGINT AUTO_INCREMENT PRIMARY KEY,
  test_session_id    VARCHAR(50) NOT NULL,
  device_name        VARCHAR(100) NOT NULL,
  browser            VARCHAR(50) NOT NULL,
  os_version         VARCHAR(20) NOT NULL,
  sample_number      INT NOT NULL,           -- 1, 2, 3, ...

  -- Full fingerprints
  tls_data           LONGTEXT NOT NULL,
  http2_data         LONGTEXT NOT NULL,

  -- Quick lookup
  ja3_hash           VARCHAR(64),
  akamai_fingerprint VARCHAR(100),

  collected_at       DATETIME NOT NULL,
  created_at         TIMESTAMP,

  -- Indexes
  INDEX idx_test_session (test_session_id),
  INDEX idx_device (device_name, browser, os_version),
  INDEX idx_sample_number (sample_number)
);
```

**Usage**: Compare multiple samples to identify what varies (GREASE) vs. what's stable (Akamai).

**ì‚¬ìš©ë²•**: ì—¬ëŸ¬ ìƒ˜í”Œì„ ë¹„êµí•˜ì—¬ ë³€ë™ë˜ëŠ” ê²ƒ(GREASE)ê³¼ ì•ˆì •ì ì¸ ê²ƒ(Akamai)ì„ ì‹ë³„.

---

## Table Relationships
## í…Œì´ë¸” ê´€ê³„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  tls_fingerprints   â”‚  (Append-only)
â”‚  - Device TLS data  â”‚
â”‚  - Collected once   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Referenced by device_name + browser + os_version
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      cookies        â”‚  (Append-only with lifecycle)
â”‚  - Original cookies â”‚
â”‚  - Updated cookies  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Used in crawl sessions
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  crawl_results      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤ crawl_details    â”‚
â”‚  - Session summary  â”‚ 1:N     â”‚ - Per-page data  â”‚
â”‚  - Aggregate stats  â”‚         â”‚ - Error details  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                              â”‚
           â”‚ session_id                   â”‚ session_id
           â”‚                              â”‚
           â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     products        â”‚         â”‚ (Same session)   â”‚
â”‚  - Ranking items    â”‚         â”‚                  â”‚
â”‚  - Ad items         â”‚         â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ device_selections   â”‚  (Independent - UI state)
â”‚  - Last selected    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    changelogs       â”‚  (Independent - documentation)
â”‚  - Version history  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚tls_variance_samples â”‚  (Independent - analysis)
â”‚  - Variance tests   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Relationships**:
1. `tls_fingerprints` + `cookies` â†’ Collected once per device
2. `crawl_results` (1) â†’ `crawl_details` (N) â†’ `products` (N)
3. All linked by `session_id` (format: `YYYYMMDD_HHMMSS`)

**ì£¼ìš” ê´€ê³„**:
1. `tls_fingerprints` + `cookies` â†’ ë””ë°”ì´ìŠ¤ë‹¹ 1íšŒ ìˆ˜ì§‘
2. `crawl_results` (1) â†’ `crawl_details` (N) â†’ `products` (N)
3. ëª¨ë‘ `session_id`ë¡œ ì—°ê²° (í˜•ì‹: `YYYYMMDD_HHMMSS`)

---

## Data Flow
## ë°ì´í„° íë¦„

### 1. Initial Device Setup (Once per device)
### 1. ì´ˆê¸° ë””ë°”ì´ìŠ¤ ì„¤ì • (ë””ë°”ì´ìŠ¤ë‹¹ 1íšŒ)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BrowserStack    â”‚
â”‚ Real Device     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ (1) Navigate to tls.peet.ws
         â”‚ (2) Collect cookies from coupang.com
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚DynamicCollector â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º tls_fingerprints (INSERT - append only)
         â”‚         - tls_data (full JSON)
         â”‚         - http2_data (Akamai fingerprint)
         â”‚         - ja3_hash, akamai_fingerprint (extracted)
         â”‚
         â””â”€â”€â”€â”€â”€â–º cookies (INSERT - original)
                   - cookie_data (PCID, sid, _abck, etc.)
                   - cookie_type = 'original'
```

### 2. Crawl Session (Multi-page)
### 2. í¬ë¡¤ë§ ì„¸ì…˜ (ë‹¤ì¤‘ í˜ì´ì§€)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   main.py       â”‚  Generate session_id
â”‚   --keyword X   â”‚  (e.g., "20251025_123456")
â”‚   --start 1     â”‚
â”‚   --end 10      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚CustomTLSCrawler â”‚  Load TLS + Cookies
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ For each page (1-10):
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º crawl_details (INSERT per attempt)
         â”‚         - session_id, page_number
         â”‚         - status (success/http2_error/akamai_challenge/...)
         â”‚         - response_size_bytes, response_time_ms
         â”‚         - is_akamai_blocked, akamai_challenge_type
         â”‚         - ranking_products_count, ad_products_count
         â”‚         - attempt_number, max_attempts
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º products (INSERT batch per successful page)
         â”‚         - session_id, page_number
         â”‚         - product_type (ranking/ad)
         â”‚         - rank_position (for ranking)
         â”‚         - ad_slot, ad_type (for ads)
         â”‚
         â””â”€â”€â”€â”€â”€â–º cookies (INSERT if Set-Cookie received)
                   - cookie_type = 'updated'
                   - session_id, page_number
```

### 3. Session Summary
### 3. ì„¸ì…˜ ìš”ì•½

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   main.py       â”‚  After all pages complete
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Aggregate results
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ crawl_results   â”‚  (INSERT once per session)
â”‚                 â”‚
â”‚ SELECT from crawl_details WHERE session_id = X
â”‚   â†’ pages_successful = COUNT(status = 'success')
â”‚   â†’ pages_failed = COUNT(status != 'success')
â”‚
â”‚ SELECT from products WHERE session_id = X
â”‚   â†’ total_ranking = COUNT(product_type = 'ranking')
â”‚   â†’ total_ads = COUNT(product_type = 'ad')
â”‚
â”‚ status = CASE
â”‚   WHEN pages_failed = 0 THEN 'success'
â”‚   WHEN pages_successful = 0 THEN 'failed'
â”‚   ELSE 'partial'
â”‚ END
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Query Patterns
## ì¿¼ë¦¬ íŒ¨í„´

### Common Queries
### ì¼ë°˜ì ì¸ ì¿¼ë¦¬

#### 1. Get Latest TLS Fingerprint
#### 1. ìµœì‹  TLS ì§€ë¬¸ ê°€ì ¸ì˜¤ê¸°

```sql
SELECT tls_data, http2_data, akamai_fingerprint
FROM tls_fingerprints
WHERE device_name = 'Samsung Galaxy S23 Ultra'
  AND browser = 'android'
  AND os_version = '13.0'
ORDER BY collected_at DESC
LIMIT 1;
```

#### 2. Get Valid Cookies
#### 2. ìœ íš¨í•œ ì¿ í‚¤ ê°€ì ¸ì˜¤ê¸°

```sql
SELECT cookie_data
FROM cookies
WHERE device_name = 'iPhone 15'
  AND browser = 'iphone'
  AND os_version = '17'
  AND is_valid = TRUE
ORDER BY collected_at DESC
LIMIT 1;
```

#### 3. Session Success Analysis
#### 3. ì„¸ì…˜ ì„±ê³µ ë¶„ì„

```sql
SELECT
  session_id,
  device_name,
  keyword,
  pages_successful,
  pages_failed,
  total_ranking,
  total_ads,
  status,
  duration_seconds
FROM crawl_results
WHERE DATE(created_at) = CURDATE()
ORDER BY created_at DESC;
```

#### 4. Akamai Block Rate by Device
#### 4. ë””ë°”ì´ìŠ¤ë³„ Akamai ì°¨ë‹¨ìœ¨

```sql
SELECT
  device_name,
  browser,
  os_version,
  COUNT(*) as total_attempts,
  SUM(is_akamai_blocked) as blocked_count,
  ROUND(100.0 * SUM(is_akamai_blocked) / COUNT(*), 2) as block_rate_pct
FROM crawl_details
GROUP BY device_name, browser, os_version
HAVING COUNT(*) >= 10  -- Minimum sample size
ORDER BY block_rate_pct ASC;  -- Best devices first
```

#### 5. Device Performance Comparison
#### 5. ë””ë°”ì´ìŠ¤ ì„±ëŠ¥ ë¹„êµ

```sql
SELECT
  device_name,
  browser,
  COUNT(DISTINCT session_id) as sessions,
  AVG(pages_successful) as avg_success_pages,
  AVG(total_ranking) as avg_ranking_products,
  AVG(total_ads) as avg_ad_products,
  AVG(duration_seconds) as avg_duration
FROM crawl_results
WHERE status IN ('success', 'partial')
GROUP BY device_name, browser
ORDER BY avg_success_pages DESC;
```

#### 6. TLS Variance Analysis
#### 6. TLS ë³€ë™ì„± ë¶„ì„

```sql
-- Check if JA3 varies but Akamai is stable
SELECT
  test_session_id,
  COUNT(DISTINCT ja3_hash) as unique_ja3,
  COUNT(DISTINCT akamai_fingerprint) as unique_akamai,
  GROUP_CONCAT(DISTINCT ja3_hash) as all_ja3_hashes,
  MAX(akamai_fingerprint) as akamai_fp
FROM tls_variance_samples
GROUP BY test_session_id;
```

#### 7. Hourly Success Rate
#### 7. ì‹œê°„ëŒ€ë³„ ì„±ê³µë¥ 

```sql
SELECT
  hour,
  COUNT(*) as total_sessions,
  SUM(status = 'success') as success_count,
  ROUND(100.0 * SUM(status = 'success') / COUNT(*), 2) as success_rate
FROM crawl_results
GROUP BY hour
ORDER BY hour;
```

#### 8. Product Distribution Analysis
#### 8. ìƒí’ˆ ë¶„í¬ ë¶„ì„

```sql
-- Average products per page by device
SELECT
  d.device_name,
  d.browser,
  AVG(d.ranking_products_count) as avg_ranking_per_page,
  AVG(d.ad_products_count) as avg_ads_per_page,
  AVG(d.total_products_count) as avg_total_per_page
FROM crawl_details d
WHERE d.status = 'success'
GROUP BY d.device_name, d.browser;
```

---

## Indexing Strategy
## ì¸ë±ì‹± ì „ëµ

### Primary Indexes (Already Applied)
### ì£¼ìš” ì¸ë±ìŠ¤ (ì´ë¯¸ ì ìš©ë¨)

1. **Device Lookups**: `(device_name, browser, os_version)`
   - Used in: All tables
   - Purpose: Fast device-specific queries

2. **Session Tracking**: `(session_id)`
   - Used in: crawl_results, crawl_details, products
   - Purpose: Link all session data

3. **Time-Based**: `(collected_at)`, `(crawled_at)`, `(created_at)`
   - Used in: All tables
   - Purpose: Time-range queries, latest data

4. **Status Filtering**: `(status)`, `(is_akamai_blocked)`, `(is_valid)`
   - Purpose: Filter success/failure, detect blocks

5. **Fingerprint Lookups**: `(ja3_hash)`, `(akamai_fingerprint)`
   - Purpose: Find devices with specific fingerprints

### Composite Index Recommendations
### ë³µí•© ì¸ë±ìŠ¤ ê¶Œì¥ì‚¬í•­

```sql
-- If frequently querying by device + time range
CREATE INDEX idx_device_time ON crawl_details (device_name, browser, os_version, crawled_at);

-- If analyzing Akamai blocks by time
CREATE INDEX idx_akamai_time ON crawl_details (is_akamai_blocked, crawled_at);

-- If analyzing products by keyword + time
CREATE INDEX idx_keyword_time ON products (keyword, collected_at);
```

---

## Usage Examples
## ì‚¬ìš© ì˜ˆì‹œ

### Python Usage with DBManager
### DBManagerë¥¼ ì‚¬ìš©í•œ Python ì‚¬ìš©ë²•

```python
from lib.db.manager import DBManager

db = DBManager()

# 1. Save TLS Fingerprint
tls_id = db.save_tls_fingerprint(
    device_name="Samsung Galaxy S23 Ultra",
    browser="android",
    os_version="13.0",
    tls_data=tls_info['tls'],        # Full TLS dict
    http2_data=tls_info['http2'],    # Full HTTP/2 dict
    collected_at=datetime.now()
)

# 2. Save Cookie
cookie_id = db.save_cookie(
    device_name="Samsung Galaxy S23 Ultra",
    browser="android",
    os_version="13.0",
    cookie_type="original",
    cookie_data=cookie_list,          # List of cookie dicts
    collected_at=datetime.now()
)

# 3. Save Products (Batch)
db.save_products_batch(
    session_id="20251025_123456",
    device_name="Samsung Galaxy S23 Ultra",
    browser="android",
    os_version="13.0",
    keyword="ì¹«ì†”",
    page_number=1,
    products_list=extracted_products,  # List of product dicts
    collected_at=datetime.now()
)

# 4. Save Crawl Detail
db.save_crawl_detail(
    session_id="20251025_123456",
    device_name="Samsung Galaxy S23 Ultra",
    browser="android",
    os_version="13.0",
    keyword="ì¹«ì†”",
    page_number=1,
    status="success",
    detail_data={
        'response_size_bytes': 512000,
        'response_time_ms': 1200,
        'http_status_code': 200,
        'is_akamai_blocked': False,
        'ranking_products_count': 27,
        'ad_products_count': 36,
        'total_products_count': 63,
        'cookie_count': 15,
        'has_pcid': True,
        'has_sid': True
    },
    crawled_at=datetime.now()
)
```

### Direct SQL Queries
### ì§ì ‘ SQL ì¿¼ë¦¬

```python
import pymysql
import json

conn = pymysql.connect(
    host='localhost',
    user='browserstack_user',
    password='your_password',
    database='browserstack',
    charset='utf8mb4'
)

cursor = conn.cursor()

# Get latest TLS for device
cursor.execute("""
    SELECT tls_data, http2_data
    FROM tls_fingerprints
    WHERE device_name = %s AND browser = %s AND os_version = %s
    ORDER BY collected_at DESC
    LIMIT 1
""", ('Samsung Galaxy S23 Ultra', 'android', '13.0'))

row = cursor.fetchone()
if row:
    tls_data = json.loads(row[0])
    http2_data = json.loads(row[1])

    akamai_fp = http2_data['akamai_fingerprint']
    ja3 = tls_data['ja3']

cursor.close()
conn.close()
```

---

## Best Practices
## ëª¨ë²” ì‚¬ë¡€

### 1. Data Retention
### 1. ë°ì´í„° ë³´ì¡´

- **TLS/Cookies**: Never delete - track variance over time
- **Products**: Keep at least 30 days for analysis
- **Crawl Details**: Keep at least 90 days for debugging
- **Crawl Results**: Keep indefinitely (small size)

- **TLS/ì¿ í‚¤**: ì ˆëŒ€ ì‚­ì œí•˜ì§€ ì•ŠìŒ - ì‹œê°„ì— ë”°ë¥¸ ë³€ë™ì„± ì¶”ì 
- **ìƒí’ˆ**: ë¶„ì„ì„ ìœ„í•´ ìµœì†Œ 30ì¼ ë³´ê´€
- **í¬ë¡¤ë§ ìƒì„¸ì •ë³´**: ë””ë²„ê¹…ì„ ìœ„í•´ ìµœì†Œ 90ì¼ ë³´ê´€
- **í¬ë¡¤ë§ ê²°ê³¼**: ë¬´ê¸°í•œ ë³´ê´€ (ì‘ì€ í¬ê¸°)

### 2. Session ID Format
### 2. ì„¸ì…˜ ID í˜•ì‹

Always use: `YYYYMMDD_HHMMSS` (e.g., `20251025_143022`)

í•­ìƒ ì‚¬ìš©: `YYYYMMDD_HHMMSS` (ì˜ˆ: `20251025_143022`)

```python
session_id = datetime.now().strftime('%Y%m%d_%H%M%S')
```

### 3. Error Handling
### 3. ì—ëŸ¬ ì²˜ë¦¬

Always save `crawl_details` even on failure - crucial for debugging!

ì‹¤íŒ¨ ì‹œì—ë„ í•­ìƒ `crawl_details` ì €ì¥ - ë””ë²„ê¹…ì— ì¤‘ìš”!

```python
try:
    result = crawler.crawl_page(page)
    db.save_crawl_detail(status='success', ...)
except Exception as e:
    db.save_crawl_detail(
        status='unknown_error',
        error_message=str(e),
        error_type=type(e).__name__,
        ...
    )
```

### 4. JSON Storage
### 4. JSON ì €ì¥

Always use `ensure_ascii=False` for Korean text:

í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ìœ„í•´ í•­ìƒ `ensure_ascii=False` ì‚¬ìš©:

```python
json.dumps(data, ensure_ascii=False)
```

### 5. Batch Inserts
### 5. ë°°ì¹˜ ì‚½ì…

Use `executemany()` for products (much faster):

ìƒí’ˆì—ëŠ” `executemany()` ì‚¬ìš© (í›¨ì”¬ ë¹ ë¦„):

```python
cursor.executemany("""
    INSERT INTO products (...) VALUES (...)
""", values_list)
```

---

## Schema Migrations
## ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜

When adding new columns, always provide defaults:

ìƒˆ ì»¬ëŸ¼ ì¶”ê°€ ì‹œ í•­ìƒ ê¸°ë³¸ê°’ ì œê³µ:

```sql
ALTER TABLE crawl_details
ADD COLUMN new_field VARCHAR(100) DEFAULT NULL;

-- Add index if needed
CREATE INDEX idx_new_field ON crawl_details (new_field);
```

---

## Troubleshooting
## ë¬¸ì œ í•´ê²°

### Check Table Sizes
### í…Œì´ë¸” í¬ê¸° í™•ì¸

```sql
SELECT
  table_name,
  ROUND((data_length + index_length) / 1024 / 1024, 2) AS size_mb,
  table_rows
FROM information_schema.TABLES
WHERE table_schema = 'browserstack'
ORDER BY (data_length + index_length) DESC;
```

### Find Slow Queries
### ëŠë¦° ì¿¼ë¦¬ ì°¾ê¸°

```sql
-- Enable slow query log
SET GLOBAL slow_query_log = 'ON';
SET GLOBAL long_query_time = 2;  -- 2 seconds

-- Check slow queries
SELECT * FROM mysql.slow_log
ORDER BY query_time DESC
LIMIT 10;
```

### Check Index Usage
### ì¸ë±ìŠ¤ ì‚¬ìš© í™•ì¸

```sql
EXPLAIN SELECT * FROM crawl_details
WHERE device_name = 'Samsung Galaxy S23 Ultra'
  AND browser = 'android';
```

---

## Changelog
## ë³€ê²½ ì´ë ¥

- **2025-10-25**: Initial documentation
  - Documented all 8 tables
  - Added query patterns and examples
  - Added best practices

---

**Last Updated**: 2025-10-25
**Maintained By**: Claude (Anthropic)
**Referenced In**: CLAUDE.md
