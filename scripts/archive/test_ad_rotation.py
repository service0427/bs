#!/usr/bin/env python3
"""
ê´‘ê³  ë¡œí…Œì´ì…˜ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ (ì„ì‹œ)

ëª©ì :
- Session ìœ ì§€ ì‹œ ê´‘ê³  ë¡œí…Œì´ì…˜ ì •ìƒ ì‘ë™ í™•ì¸
- 1í˜ì´ì§€ â†’ 2í˜ì´ì§€ â†’ 1í˜ì´ì§€ í¬ë¡¤ë§
- ë­í‚¹ ìƒí’ˆ ì¼ì¹˜, ê´‘ê³  ìœ„ì¹˜ ì¼ì¹˜, ê´‘ê³  ë‚´ìš© ë¡œí…Œì´ì…˜ í™•ì¸

ì‚¬ìš©ë²•:
    python test_ad_rotation.py --keyword "ë°©ì„"
    python test_ad_rotation.py --keyword "ì¿ ì…˜" --device-name "Samsung Galaxy S22"
"""

import argparse
import json
import os
import sys
import time
import random
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


class TeeLogger:
    """ì½˜ì†”ê³¼ íŒŒì¼ì— ë™ì‹œ ì¶œë ¥í•˜ëŠ” ë¡œê±°"""

    def __init__(self, log_file):
        self.terminal = sys.stdout
        self.log = open(log_file, 'w', encoding='utf-8')
        self.log_file = log_file

    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
        self.log.flush()  # ì¦‰ì‹œ íŒŒì¼ì— ì“°ê¸°

    def flush(self):
        self.terminal.flush()
        self.log.flush()

    def close(self):
        if self.log:
            self.log.close()

from lib.crawler.custom_tls import CustomTLSCrawler
from lib.utils.ad_position_analyzer import AdPositionAnalyzer
from lib.device.selector import select_device
from lib.settings import ensure_directories, get_device_fingerprint_dir


def save_html(html_content, filename, output_dir='data/test_html'):
    """HTML ì €ì¥"""
    os.makedirs(output_dir, exist_ok=True)
    filepath = os.path.join(output_dir, filename)

    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(html_content)

    print(f"  ğŸ’¾ HTML ì €ì¥: {filepath}")
    return filepath


def print_session_info(crawler, label="Session ì •ë³´"):
    """Session ì¿ í‚¤ ì •ë³´ ì¶œë ¥"""
    print(f"\n{'='*80}")
    print(f"{label}")
    print(f"{'='*80}")

    if hasattr(crawler.session, 'cookies'):
        cookies = crawler.session.cookies

        # PCID í™•ì¸
        if 'PCID' in cookies:
            pcid = str(cookies.get('PCID', ''))
            print(f"  âœ“ PCID: {pcid[:40]}... (Session ìœ ì§€)")
        else:
            print(f"  âŒ PCID ì—†ìŒ")

        # sid í™•ì¸
        if 'sid' in cookies:
            sid = str(cookies.get('sid', ''))
            print(f"  âœ“ sid: {sid[:40]}...")
        else:
            print(f"  âš ï¸ sid ì—†ìŒ")

        print(f"  âœ“ ì´ ì¿ í‚¤: {len(cookies)}ê°œ")
    else:
        print(f"  âŒ Session ì¿ í‚¤ ì—†ìŒ")

    print(f"{'='*80}\n")


def test_ad_rotation(keyword, device_name=None, browser=None, os_version=None):
    """
    ê´‘ê³  ë¡œí…Œì´ì…˜ í…ŒìŠ¤íŠ¸

    Args:
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
        device_name: ë””ë°”ì´ìŠ¤ ì´ë¦„ (Noneì´ë©´ ì¸í„°ë™í‹°ë¸Œ ì„ íƒ)
        browser: ë¸Œë¼ìš°ì € (Noneì´ë©´ ì¸í„°ë™í‹°ë¸Œ ì„ íƒ)
        os_version: OS ë²„ì „ (Noneì´ë©´ ì¸í„°ë™í‹°ë¸Œ ì„ íƒ)
    """
    print("\n" + "="*80)
    print("ê´‘ê³  ë¡œí…Œì´ì…˜ ê²€ì¦ í…ŒìŠ¤íŠ¸")
    print("="*80)
    print(f"ê²€ìƒ‰ í‚¤ì›Œë“œ: {keyword}")
    print(f"í…ŒìŠ¤íŠ¸ ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)

    # ë””ë°”ì´ìŠ¤ ì„ íƒ
    if device_name and browser:
        print(f"\n[ë””ë°”ì´ìŠ¤] {device_name} / {browser}")
        device_config = {
            'device': device_name,
            'browser': browser,
            'os_version': os_version  # ëª…ë ¹í–‰ì—ì„œ ì „ë‹¬ë°›ìŒ
        }
    else:
        print("\n[ë””ë°”ì´ìŠ¤ ì„ íƒ]")
        device_config = select_device()
        device_name = device_config['device']
        browser = device_config['browser']

    # Crawler ìƒì„± (ë‹¨ì¼ Session ì‚¬ìš©)
    print(f"\n[Crawler ìƒì„±]")
    print(f"  âœ“ Session ê°ì²´ ìƒì„± (TLS ì—°ê²° ì¬ì‚¬ìš©)")
    crawler = CustomTLSCrawler(device_name, browser, device_config=device_config)

    # íƒ€ì„ìŠ¤íƒ¬í”„
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # ===================================================================
    # 1. ì²« ë²ˆì§¸ í˜ì´ì§€ ë°©ë¬¸
    # ===================================================================
    print(f"\n{'='*80}")
    print(f"[1] í˜ì´ì§€ 1 - ì²« ë°©ë¬¸")
    print(f"{'='*80}")

    result_page1_v1 = crawler.crawl_page(keyword=keyword, page=1)

    if not result_page1_v1.get('success'):
        print(f"âŒ 1í˜ì´ì§€ í¬ë¡¤ë§ ì‹¤íŒ¨")
        return

    # HTML ì €ì¥
    html_page1_v1 = result_page1_v1.get('html', '')
    save_html(html_page1_v1, f'{timestamp}_page1_visit1.html')

    # ë¶„ì„
    analysis_page1_v1 = AdPositionAnalyzer.analyze_html(html_page1_v1)

    print(f"\n[ê²°ê³¼]")
    print(f"  ë­í‚¹ ìƒí’ˆ: {analysis_page1_v1['ranking_count']}ê°œ")
    print(f"  ê´‘ê³ : {analysis_page1_v1['ad_count']}ê°œ")
    print(f"  ê´‘ê³  ìœ„ì¹˜: {analysis_page1_v1['ad_positions'][:10]}..." if len(analysis_page1_v1['ad_positions']) > 10 else f"  ê´‘ê³  ìœ„ì¹˜: {analysis_page1_v1['ad_positions']}")

    # Session ì •ë³´
    print_session_info(crawler, "[Session ì •ë³´ - 1í˜ì´ì§€ í›„]")

    # í˜ì´ì§€ ì´ë™ ë”œë ˆì´ (ì‚¬ëŒì²˜ëŸ¼ í–‰ë™)
    delay = random.uniform(1.5, 3.0)
    print(f"\nâ³ ë‹¤ìŒ í˜ì´ì§€ ëŒ€ê¸° ì¤‘... ({delay:.1f}ì´ˆ)")
    time.sleep(delay)

    # ===================================================================
    # 2. ë‘ ë²ˆì§¸ í˜ì´ì§€ ë°©ë¬¸ (Session ìœ ì§€)
    # ===================================================================
    print(f"\n{'='*80}")
    print(f"[2] í˜ì´ì§€ 2 ë°©ë¬¸ (Session ìœ ì§€)")
    print(f"{'='*80}")

    result_page2 = crawler.crawl_page(keyword=keyword, page=2)

    if not result_page2.get('success'):
        print(f"âŒ 2í˜ì´ì§€ í¬ë¡¤ë§ ì‹¤íŒ¨")
        return

    # HTML ì €ì¥
    html_page2 = result_page2.get('html', '')
    save_html(html_page2, f'{timestamp}_page2.html')

    # ë¶„ì„
    analysis_page2 = AdPositionAnalyzer.analyze_html(html_page2)

    print(f"\n[ê²°ê³¼]")
    print(f"  ë­í‚¹ ìƒí’ˆ: {analysis_page2['ranking_count']}ê°œ")
    print(f"  ê´‘ê³ : {analysis_page2['ad_count']}ê°œ")

    # Session ì •ë³´
    print_session_info(crawler, "[Session ì •ë³´ - 2í˜ì´ì§€ í›„]")

    # í˜ì´ì§€ ì´ë™ ë”œë ˆì´ (ì‚¬ëŒì²˜ëŸ¼ í–‰ë™)
    delay = random.uniform(1.5, 3.0)
    print(f"\nâ³ í˜ì´ì§€ 1 ì¬ë°©ë¬¸ ëŒ€ê¸° ì¤‘... ({delay:.1f}ì´ˆ)")
    time.sleep(delay)

    # ===================================================================
    # 3. ì²« ë²ˆì§¸ í˜ì´ì§€ ì¬ë°©ë¬¸ (Session ìœ ì§€)
    # ===================================================================
    print(f"\n{'='*80}")
    print(f"[3] í˜ì´ì§€ 1 - ì¬ë°©ë¬¸ (Session ìœ ì§€)")
    print(f"{'='*80}")

    result_page1_v2 = crawler.crawl_page(keyword=keyword, page=1)

    if not result_page1_v2.get('success'):
        print(f"âŒ 1í˜ì´ì§€ ì¬ë°©ë¬¸ í¬ë¡¤ë§ ì‹¤íŒ¨")
        return

    # HTML ì €ì¥
    html_page1_v2 = result_page1_v2.get('html', '')
    save_html(html_page1_v2, f'{timestamp}_page1_visit2.html')

    # ë¶„ì„
    analysis_page1_v2 = AdPositionAnalyzer.analyze_html(html_page1_v2)

    print(f"\n[ê²°ê³¼]")
    print(f"  ë­í‚¹ ìƒí’ˆ: {analysis_page1_v2['ranking_count']}ê°œ")
    print(f"  ê´‘ê³ : {analysis_page1_v2['ad_count']}ê°œ")
    print(f"  ê´‘ê³  ìœ„ì¹˜: {analysis_page1_v2['ad_positions'][:10]}..." if len(analysis_page1_v2['ad_positions']) > 10 else f"  ê´‘ê³  ìœ„ì¹˜: {analysis_page1_v2['ad_positions']}")

    # Session ì •ë³´
    print_session_info(crawler, "[Session ì •ë³´ - 1í˜ì´ì§€ ì¬ë°©ë¬¸ í›„]")

    # ===================================================================
    # 4. ë¹„êµ ë¶„ì„
    # ===================================================================
    print(f"\n{'='*80}")
    print(f"[4] ë¹„êµ ë¶„ì„: 1í˜ì´ì§€ ì²« ë°©ë¬¸ vs ì¬ë°©ë¬¸")
    print(f"{'='*80}")

    comparison = AdPositionAnalyzer.compare_results(
        analysis_page1_v1,
        analysis_page1_v2,
        label1="ì²« ë°©ë¬¸",
        label2="ì¬ë°©ë¬¸"
    )

    AdPositionAnalyzer.print_comparison(comparison, label1="ì²« ë°©ë¬¸", label2="ì¬ë°©ë¬¸")

    # ===================================================================
    # 5. ê²°ê³¼ ì €ì¥
    # ===================================================================
    result_data = {
        'timestamp': timestamp,
        'keyword': keyword,
        'device': device_name,
        'browser': browser,
        'page1_visit1': {
            'ranking_count': analysis_page1_v1['ranking_count'],
            'ad_count': analysis_page1_v1['ad_count'],
            'ad_positions': analysis_page1_v1['ad_positions']
        },
        'page2': {
            'ranking_count': analysis_page2['ranking_count'],
            'ad_count': analysis_page2['ad_count']
        },
        'page1_visit2': {
            'ranking_count': analysis_page1_v2['ranking_count'],
            'ad_count': analysis_page1_v2['ad_count'],
            'ad_positions': analysis_page1_v2['ad_positions']
        },
        'comparison': comparison
    }

    result_file = f'data/test_html/{timestamp}_result.json'
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {result_file}")

    print(f"\n{'='*80}")
    print(f"í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"{'='*80}\n")


def main():
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    logs_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'data', 'logs')
    os.makedirs(logs_dir, exist_ok=True)

    # ë¡œê·¸ íŒŒì¼ ì„¤ì •
    now = datetime.now()
    log_filename = f"test_ad_rotation_{now.strftime('%Y%m%d_%H%M%S')}.log"
    log_filepath = os.path.join(logs_dir, log_filename)

    # stdoutì„ TeeLoggerë¡œ êµì²´ (ì½˜ì†” + íŒŒì¼ ë™ì‹œ ì¶œë ¥)
    tee_logger = TeeLogger(log_filepath)
    original_stdout = sys.stdout
    sys.stdout = tee_logger

    try:
        print(f"ğŸ“ ë¡œê·¸ íŒŒì¼: {log_filepath}\n")

        parser = argparse.ArgumentParser(description='ê´‘ê³  ë¡œí…Œì´ì…˜ ê²€ì¦ í…ŒìŠ¤íŠ¸')
        parser.add_argument('--keyword', type=str, default='ë°©ì„', help='ê²€ìƒ‰ í‚¤ì›Œë“œ (ê¸°ë³¸ê°’: ë°©ì„)')
        parser.add_argument('--device-name', type=str, help='ë””ë°”ì´ìŠ¤ ì´ë¦„ (ì˜ˆ: Samsung Galaxy S22)')
        parser.add_argument('--browser', type=str, help='ë¸Œë¼ìš°ì € (ì˜ˆ: samsung, android, iphone)')
        parser.add_argument('--os-version', type=str, help='OS ë²„ì „ (ì˜ˆ: 12_0, 10_0)')

        args = parser.parse_args()

        # ë””ë ‰í† ë¦¬ ìƒì„±
        ensure_directories()
        os.makedirs('data/test_html', exist_ok=True)

        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_ad_rotation(
            keyword=args.keyword,
            device_name=args.device_name,
            browser=args.browser,
            os_version=args.os_version
        )

        print(f"\n{'='*80}")
        print(f"ğŸ“ ì „ì²´ ë¡œê·¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(f"   {log_filepath}")
        print(f"{'='*80}\n")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ì ì¤‘ë‹¨ (Ctrl+C)")
    except Exception as e:
        print(f"\n\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # stdout ë³µì›
        sys.stdout = original_stdout
        tee_logger.close()


if __name__ == '__main__':
    main()
